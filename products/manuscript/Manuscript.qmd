---
title: "Which Mushroom will kill you?! "
subtitle: ""
author: Alex Martinez
date: "`r Sys.Date()`"
format:
  docx:
    toc: false
    number-sections: true
    highlight-style: github
bibliography: ../../assets/dataanalysis-references.bib
csl: ../../assets/apa.csl
---

The structure below is one possible setup for a data analysis project (including the course project). For a manuscript, adjust as needed. You don't need to have exactly these sections, but the content covering those sections should be addressed.

This uses MS Word as output format. [See here](https://quarto.org/docs/output-formats/ms-word.html) for more information. You can switch to other formats, like html or pdf. See [the Quarto documentation](https://quarto.org/) for other formats.

```{r, echo=FALSE, message=FALSE}
# load a few R packages
library(here)
library(knitr)
```

# Summary/Abstract

**Briefly describe what the data is, how it was collected, where you will get (or got) it from. How many observations do you have, what was measured? Anything else important to report about the data?**

The dataset I will be using is from Kaggle called [Muchroom Dataset](https://www.kaggle.com/datasets/prishasawhney/mushroom-dataset/data). The kaggle version is a cleaned version of the original [Mushroom Dataset for Binary Classification](https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset), available at UCI Library. The data set contains 9 columns and 54036 rows. There is one variable that is binary which indicates if the mushroom is edible or not. The following 8 variables are different features of the mushroom. Here are those variables.

Cap Diameter

Cap Shape

Gill Attachment

Gill Color

Stem Height

Stem Width

Stem Color Season

Target Class - Is it edible or not?

**At this stage you are not required to already have and show the data, but if you do, even better. Then add a few lines of code which load the data and using some of the commands you learned about, provide summary descriptions of the data.**

I am still working on importing and creating summary descriptions of my dataset.

**Explain the question you want to answer using the data. What will be your outcome(s) of interest (if any)? What (if any) specific predictors will you focus on? What relations/patterns are you looking for in the data?**

The main quesiton I want to answer is the following. *Determine what is the best model to predict if a mushroom is edible or not using the following 8 variables are your predictors.*

Cap Diameter

Cap Shape

Gill Attachment

Gill Color

Stem Height

Stem Width

Stem Color Season

Target Class - Is it edible or not?

I will focus on each predictor variable to see what is most significant in predicting if a mushroom is edible or not.

**As much as you know, suggest how you will analyze it. At this stage in the course, we haven’t covered analysis approaches yet, so you can keep things vague and non-technical here.**

I will run multiple different regression models to determine which is best at predicting the predictor varible. Some models I will consider are, linear/multilinear regression, logistic regression, decision tree models, etc.

**You are allowed, but not yet required, to provide background information for the question you plan to answer. For instance you can describe why it’s an interesting question, who else has done similar analyses, how your analysis will be new/different, etc. Similar to what you read in an introduction to a research paper. For the final report, you’ll need these parts. For part 1, they are not required, but you are welcome to already write down some of that.**

I want to enhance my modeling skills by trying multiple models to obtain the largest accuracy. Something unique that I will be doing compared to everything Ive seen on Kaggle for this data set is that I will be using R while everyone else used Python.

**Eventually, for your final report, what you write for this part will go into different sections of the full report. Some will go into the introduction, some in the methods section. You can already place these items there, or for now just write them as a single section.**

Ok thanks.

### BELOW IS WHAT WILL GET DONE THROUGHOUT THE SEMESTER (:

{{< pagebreak >}}

# Introduction

## General Background Information

*Provide enough background on your topic that others can understand the why and how of your analysis*

## Description of data and data source

This dataset is a cleaned version of the original [Mushroom Dataset for Binary Classification](https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset) Available at UCI Library. This dataset was cleaned using various techniques such as Modal imputation, one-hot encoding, z-score normalization, and feature selection. It contains 9 columns:

1.  Cap Diameter

2.  Cap Shape

3.  Gill Attachment

4.  Gill Color

5.  Stem Height

6.  Stem Width

7.  Stem Color

8.  Season

9.  Target Class - Is it edible or not?

The Target Class contains two values - 0 or 1 - where 0 refers to edible and 1 refers to poisonous.

## Questions/Hypotheses to be addressed

*Using the Variables listed above, what is the best predictive model to determine if a mushroom is edible or not.*

{{< pagebreak >}}

# Methods

*Describe your methods. That should describe the data, the cleaning processes, and the analysis approaches. You might want to provide a shorter description here and all the details in the supplement.*

The modeling methods I will be using are the following


A random forest model is trained using 100 trees.
A decision tree is just one simple decision tree that is evaluated.
A lighGBM model is efficient for large datasets but can still work on smaller ones.
GBM uses cross-validation to find the optimal number of trees.


## Data aquisition

*The data is from the Kaggle website that has been listed above. It is a CSV file with 9 variables and \~50,000 rows.*

## Data import and cleaning

The data is pretty cleaned already espescially since it is only 9 variables and \~50,000 rows. Here is the import

```{r}
library(tidyverse)
getwd()
mushrooms <- read.csv('C:/Users/alexm/Downloads/Pract 2/AlexMartinez-Analysis-Pract2/data/mushroom_cleaned.csv')


## Lets Explore the data
head(mushrooms)
str(mushrooms)

summary(mushrooms)
```

## Statistical analysis

*Explain anything related to your statistical analyses.*

{{< pagebreak >}}

# Results

## Exploratory/Descriptive analysis

*Use a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project.*

```{r}
#Exploring all varibles with some visualizations
mushrooms %>% ggplot(aes(x = cap.diameter)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  theme_minimal()

ggplot(mushrooms, aes(x = factor(cap.shape))) +
  geom_bar(fill = 'black') +
  labs(x = "Cap Shape", y = "Frequency", title = "Frequency of Mushroom Cap Shape") +
  theme_minimal()

ggplot(mushrooms, aes(x = factor(gill.attachment))) +
  geom_bar(fill = 'black') +
  labs(x = "Gill Attachment", y = "Frequency", title = "Frequency of Mushroom Gill Attachment") +
  theme_minimal()

ggplot(mushrooms, aes(x = factor(gill.color))) +
  geom_bar(fill = 'black') +
  labs(x = "Gill Color", y = "Frequency", title = "Frequency of Mushroom Gill Color") +
  theme_minimal()

ggplot(mushrooms, aes(x = stem.height)) +
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
  labs(x = "Stem Height", y = "Frequency", title = "Histogram of Stem Height") +
  theme_minimal()
ggplot(mushrooms, aes(x = stem.height)) +
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
  labs(x = "Stem Height", y = "Frequency", title = "Histogram of Stem Height") +
  theme_minimal()


ggplot(mushrooms, aes(x = stem.width)) +
  geom_histogram(binwidth = 50, fill = "skyblue", color = "black") +
  labs(x = "Stem Width", y = "Frequency", title = "Histogram of Stem Width") +
  theme_minimal()
ggplot(mushrooms, aes(y = stem.width)) +
  geom_boxplot(fill = "skyblue", color = "black") +
  labs(y = "Stem Width", title = "Boxplot of Stem Width") +
  theme_minimal()

ggplot(mushrooms, aes(x = factor(stem.color))) +
  geom_bar(fill = 'black') +
  labs(x = "Stem Color", y = "Frequency", title = "Frequency of Mushroom Stem Color") +
  theme_minimal()


ggplot(mushrooms, aes(x = factor(class))) +
  geom_bar(fill = 'red') +
  labs(x = "Class", y = "Frequency", title = "Frequency of Mushroom Classes") +
  theme_minimal()

  

#lets view a correlation matrix of all the variables
library(corrplot)
correlation_matrix <- cor(mushrooms)
print(correlation_matrix)

# correlation matrix heatmap
corrplot(correlation_matrix, method = "color")
```




## Basic statistical analysis

*To get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any "p\<0.05 means statistical significance" interpretation is not valid.*



## Full analysis

*Use one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here.*


```{r}
#libraries needed
library(tidyverse)
library(caret)
library(randomForest)
library(rpart)
library(lightgbm)
library(gbm)
```
```{r}
data <- mushrooms

# Convert class to factor
data$class <- as.factor(data$class)

# Scale the specified columns
scaled_data <- data %>%
  mutate(across(c(cap.diameter, stem.width, season), scale))

# Convert necessary columns to factors
scaled_data <- scaled_data %>%
  mutate(across(c(cap.shape, gill.attachment, gill.color, stem.color), as.factor))

# Split data into features and target variable
X <- scaled_data %>%
  select(-class)
y <- scaled_data$class

# Set seed for reproducibility
set.seed(123)

# Create training and testing datasets
trainIndex <- createDataPartition(y, p = 0.9, list = FALSE)
X_train <- X[trainIndex, ]
X_test <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test <- y[-trainIndex]

# Train Random Forest Classifier
rf_model <- randomForest(x = X_train, y = y_train, ntree = 100)
rf_pred <- predict(rf_model, X_test)
rf_accuracy <- mean(rf_pred == y_test)
print(paste("Random Forest Accuracy:", rf_accuracy))

# Train Decision Tree Classifier
dt_model <- rpart(class ~ ., data = data.frame(X_train, class = y_train))
dt_pred <- predict(dt_model, X_test, type = "class")
dt_accuracy <- mean(dt_pred == y_test)
print(paste("Decision Tree Accuracy:", dt_accuracy))

# Convert data to matrix format for LightGBM
X_train_matrix <- as.matrix(X_train)
X_test_matrix <- as.matrix(X_test)

# Train LightGBM Classifier
lgb_train <- lgb.Dataset(data = X_train_matrix, label = as.numeric(y_train) - 1)
params <- list(objective = "multiclass", num_class = length(levels(y_train)))
lgb_model <- lgb.train(params, lgb_train, 100)
lgb_pred <- predict(lgb_model, X_test_matrix)
lgb_pred_class <- factor(max.col(lgb_pred) - 1, levels = 0:(length(levels(y_train)) - 1))
lgb_accuracy <- mean(lgb_pred_class == y_test)
print(paste("LightGBM Accuracy:", lgb_accuracy))

# Train GBM Classifier using gbm package
gbm_model <- gbm(class ~ ., data = data.frame(X_train, class = y_train), distribution = "multinomial", n.trees = 100, cv.folds = 5, interaction.depth = 3, shrinkage = 0.01, n.minobsinnode = 10)
gbm_pred <- predict(gbm_model, newdata = X_test, n.trees = gbm.perf(gbm_model, method = "cv"), type = "response")
gbm_pred_class <- factor(max.col(gbm_pred), levels = 1:length(levels(y_train)) - 1)
gbm_accuracy <- mean(gbm_pred_class == y_test)
print(paste("GBM Accuracy:", gbm_accuracy))
```
Best Performance
```{r}
#best variables
print(paste("Random Forest Accuracy:", rf_accuracy))
var_importance <- importance(rf_model)
var_importance_df <- data.frame(Variable = rownames(var_importance), 
                                Importance = var_importance[, 'MeanDecreaseGini'])

# Print the variable importance
print(var_importance_df)

# Plot variable importance
library(ggplot2)
ggplot(var_importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  xlab("Variable") +
  ylab("Importance") +
  ggtitle("Variable Importance from Random Forest Model") +
  theme_minimal()
```



{{< pagebreak >}}

# Discussion

## Summary and Interpretation

The four classification models we used to help determine what mushroom is edible or not is the Random Forest, Decision Tree, LightBGM, and GBM classifier. We will determine which one is the best by looking at its performance on our test dataset.

A random forest model is trained using 100 trees.
A decision tree is just one simple decision tree that is evaluated.
A lighGBM model is efficient for large datasets but can still work on smaller ones.
GBM uses cross-validation to find the optimal number of trees.


## Conclusions

Our best model is the random forest model. It has an accuracy of 98.9% of predicting which mushrooms are edible using the following factors: Stem Width, Gill Attachment, Stem Color, Gill Color, Cap Shape, Stem Height, Cap Diameter and Season. From these factors, the top four that are best at predicting if a mushroom is edible or not base on that factor alone are Stem Width, Gill Attachment, Stem Color, Gill Color ordered from most importance to least importance. 

```{r}
# Extract the top 4 important variables
top4_vars <- head(var_importance_df[order(-var_importance_df$Importance), ], 4)
print(top4_vars)
poisonous_mushrooms <- subset(mushrooms, class == 0)
summary(poisonous_mushrooms[, top4_vars$Variable])

boxplot(poisonous_mushrooms$stem.width)
boxplot(poisonous_mushrooms$gill.attachment)
boxplot(poisonous_mushrooms$stem.color)
boxplot(poisonous_mushrooms$gill.color)
```
We see from the top 4 most important variables that help determine if a mushroom is edible or not have the following in common. A stem width of 1157, gill attachment of 2, stem color of code 11 and gill color of code 10. So if you have a mushroom with any of these features, be safe!

{{< pagebreak >}}

# References
[Dataset](https://www.kaggle.com/datasets/prishasawhney/mushroom-dataset/data). The kaggle version is a cleaned version of the original [Mushroom Dataset for Binary Classification](https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset), available at UCI Library.